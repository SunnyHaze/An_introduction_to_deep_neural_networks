# BP算法
人工智能 -> 深度神经网络 -> BP学习算法

局部函数（结合函数）$f_i^l$

## Supervised Learning监督学习
输入数据为二元对$D=\{(x,y^l)\}$  
使prediction更加接近目标  
利用度量函数cost function进行度量
$J(a^l,y^l) = J(w^1,...,w^{L-1})$
最简单采用欧氏距离
$$J=\frac{1}{2}\sum^{n_l}_{j=1}e^2_j=J(a^l,y^l) = J(w^1,...,w^{L-1})$$
利用梯度下降法寻觅最佳解:
$$\frac{\partial J}{\partial w^l_{ji}}$$
但是如何高效计算梯度函数呢，利用BP算法求解梯度是正确解。
相邻梯度与神经元的关系。
$$\frac{\partial J}{\partial w^l_{ji}}=\delta^{l+1}_{ji} \cdot a^l_i$$
Updating rule
$$w^l_{ji}\lArr w^l_{ji}-\frac{\partial J(x,y)}{\partial W_{ji}^l}$$

## 流程
1. 准备数据
   1. 准备数据集
   2. 训练集80%
   3. 测试集20%
   4. 数据增广（运用可能的方式拓展）
2. 设计网络结构
   1. 设计多少层（网络深度）
      1. 不能低于3层
      2. 越少越好，为了简化计算
      3. 由经验决定，不一定有特别好的量化方法
      4. 从最后一层开始，确定个数，只有外部输入（一般看有几个维度），然后确定第一层的输入个数（也是根据输入向量的维度）
   2. 神经元个数
      1. 外部输入的个数
      2. 内部表达的个数
   3. 结合函数选用什么样的函数
      1. 线性/非线性函数
3. 初始化矩阵
   1. 初始化连接权矩阵$W^n$
      1. 一般直接取随机值先生成
      2. 初始化内部输入值
         1. 取0/取1
      3. 反向计算需要一个学习算法“learning rate” $\alpha$
4. 定义度量函数$J$
   1. 刻画目标点和实际点之间的距离
   2. 常用欧氏距离
$$J=\frac{1}{2}\sum^{n_l}_{j=1}e^2_j$$
5. 定义评价指标
   1. $$Accuracy=\frac{number\ of\ correct\ prediction}{number\ of\ samples}$$
6. 训练网络
7. 测试网络
   1. 训练集要保证正确，90%可以接受，特殊行业要尽可能高，比如：人脸识别
   2. 测试集要尽可能提高正确率
8. 保存整个网络
   1. 即训练好的模型，各个节点的连接权矩阵$W$和结合函数$f$是重点
9.  将训练好的网络运用到软件
    1. 此时的数据已经没有标签了
    2. 直接生成结果
## 应用神经网络的实例――手写体数字识别
* 经典数据集：**MNIST_small**和**MNIST**
  * 每一个手写字母被整理成28×28的图片，来自纽约大学鲁春教授。
  * 分成了不相关的两个数据集训练集10000个，测试集2000个
  * 数据集被量化成向量
  * 第一层有784维的向量，最后的有10位的向量，按照5层切片，有256，128，64这些中间层
  * 结合函数用Sigmoid function
    * $$f(z)=\frac{1}{1+e^{-z}}$$
    * 考虑到要介于值域之间


