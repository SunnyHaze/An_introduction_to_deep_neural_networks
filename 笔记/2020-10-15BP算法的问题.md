# 2020-10-15BP算法的一些问题
## 复习
* 全局函数J
$$\frac{\partial J}{\partial Z^l_i}=\delta^l_i$$
$$\frac{\partial J}{\partial w^l_{ji}} =  \delta^j_i\cdot$$
* 局部函数$f^l_j$
$$a^l_i=f^l_i(z^l_i)$$
$funcktion\ fc(w^l,a^l)$<br>
$for\ i = 1:n_{l+1}$

## BP的种种细节
### 网络的结构
#### Recurrent Neural Networks(RNN,回复神经网络，递归神经网络)
* 共享连接权矩阵（CNN）
* 每一层的神经元个数相同
#### 结合函数不同
* 每两个不同的神经元的结合函数都可以不一样，同一层里可以采用Sigmoid或者线性函数等等
#### DenseNets
* 由线性神经元连接，第一层对第三四五层有联系，以此类推
### 网络的学习算法
1. 大脑中的BP算法
   1. D.O.Hebb 认知生物生理学之父
   2. “如果一个突触两端的神经元，如果被同时结合的话，那么该连接强度将会增强”
   3. 由此在大脑中类似的学习算法 
   $$w^l_{ji}\leftarrow w^l_{ji}+F(z^{l+1}_j,z^l_i)$$
   4. 特别的，将：
    $$F(z^{l+1}_j,z^l_i)=-\alpha\cdot(\frac{\partial J}{\partial z^{l+1}_{j}})\cdot f(z^l_i)$$
   5. 可以一定程度上看作大脑中存在BP算法的实现
### 目标输出
* AlphaGo的学习
  * 每一步只有两个数据，一个是当前棋盘状态，一个是“大师的落子点”
* 曲线拟合
  * 训练集为目标的输入，和对应的一维输出
* 数值语音数据，即 **“语音转数字”**
  * 2983维的数据，整合到10维
### 预测输出
* 注意控制结合函数，按照值域等特征。
### 输入情况
* 可以拆分在不同的层中间插入额外输入
### 性能函数
* J常用欧氏距离
* $$\delta^L_i=\frac{\partial J}{\partial z^l_i}=(a^L_i-y^L_i)\cdot \dot{f}()$$
* 多用交叉商
* 方便教学应用欧氏距离，但是容易产生很多“极小值点”影响结果
* 选择一个好的代价函数，会很大影响网络的性能

### 网络的深度
* 网络层数为2，称为浅层神经网络（Shallow neural network)
* 深度神经网络，L>2（Deep neural network)
* 例：**XOR问题**
  * 两层的网络难以解决本问题
    * 网络平面中存在的决策线$w_1x_1+w_2x_2+w_3=0$
  * 至少需要三层去解决XOR问题
* **梯度消失问题**
### 训练数据
* 训练集的过拟合，数据要**多**！
* 至少不能少于网络的参数的个数
* 神经网络的成功起源于大数据的成功
## 作业
* 数字转语音